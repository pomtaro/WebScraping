{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime as dt\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: url\n",
    "return: html\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_feed_html_soup(driver, url):\n",
    "    retries = 3\n",
    "    i = 0\n",
    "    \n",
    "    while i < retries:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            return html_soup\n",
    "        except TimeoutException:\n",
    "            i += 1\n",
    "            print('Timeout, Retrying... {} / {}'.format((i), retries))\n",
    "            driver.refresh()\n",
    "            print('driver was refreshed')\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "@retry(tries=3, delay=5)\n",
    "def get_feed_html_soup_retry(driver, url):\n",
    "    driver.get(url)\n",
    "    html = driver.page_source.encode('utf-8')\n",
    "    html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "    print('retry')\n",
    "    return html_soup\n",
    "\n",
    "\n",
    "def get_feed_html_soup_newdriver(driver, url):\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "            return driver, html_soup\n",
    "    \n",
    "        except TimeoutException:\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            driver = login(driver, url, 'feed')  # ログイン\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: mid_list\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_mid_list(html_soup):\n",
    "    mid_list = []\n",
    "    div_elements = html_soup.find_all('div', {'id': 'pl_feedlist_index'})\n",
    "    div_elements = div_elements[0].find_all('div', {'class': 'card-wrap'})\n",
    "    for elem in div_elements:\n",
    "        mid = elem.get('mid')\n",
    "        if type(mid) == str:\n",
    "            mid_list.append(mid)\n",
    "    \n",
    "    return mid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: mid\n",
    "return: account_name, feed_time, sentence, share, comment, good\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_feed_info(html_soup, mid):\n",
    "    div_mid = html_soup.find_all('div', {'mid': mid})\n",
    "    \n",
    "    # アカウント名\n",
    "    account_name = div_mid[0].find('p').get('nick-name')\n",
    "    \n",
    "    # 時刻\n",
    "    feed_time = ''.join(div_mid[0].find_all('p', {'class': 'from'})[0].find('a').text.split())\n",
    "    try:\n",
    "        if '今天' in feed_time:     \n",
    "            feed_time = dt.strftime(dt.now(), '%Y-%m-%d ') + feed_time.split('今天')[1] + ':00'\n",
    "        elif '前' in feed_time:\n",
    "            feed_time = dt.strftime(dt.now(), '%Y-%m-%d %H:%M:%S')\n",
    "        elif '秒' in feed_time:\n",
    "            feed_time = dt.strftime(dt.now(), '%Y-%m-%d %H:%M:%S')\n",
    "        elif len(feed_time) < 12:\n",
    "            feed_time = dt.strptime(feed_time, '%m月%d日%H:%M').replace(year=2019)\n",
    "        else:\n",
    "            feed_time = dt.strptime(feed_time, '%Y年%m月%d日%H:%M')\n",
    "    except:\n",
    "        feed_time = 'not detected'\n",
    "    # 本文\n",
    "    sentence = ''.join(div_mid[0].find('p').text.split())\n",
    "    \n",
    "    # シェア、コメント、いいね\n",
    "    share = ''\n",
    "    comment = ''\n",
    "    suda_data = ''\n",
    "    good = ''\n",
    "    bottom_items = div_mid[0].find_all('div', {'class': 'card-act'})[0].find_all('li')\n",
    "    for bottom_item in bottom_items:\n",
    "        \n",
    "        if bottom_item.text == '收藏':\n",
    "            pass\n",
    "        elif '转发' in bottom_item.text:\n",
    "            if len(bottom_item.text.split()) < 2:\n",
    "                share = '0'\n",
    "            else:\n",
    "                share = bottom_item.text.split()[1]\n",
    "        elif '评论' in bottom_item.text:\n",
    "            if len(bottom_item.text.split()) < 2:\n",
    "                comment = '0'\n",
    "            else:\n",
    "                comment = bottom_item.text.split()[1]\n",
    "                suda_data = bottom_item.find_all('a')[0].get('suda-data')\n",
    "        else:\n",
    "            if len(bottom_item.text.split()) < 1:\n",
    "                good = '0'\n",
    "            else:\n",
    "                good = bottom_item.text   \n",
    "    \n",
    "    return account_name, feed_time, sentence, share, comment, suda_data, good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: comment_id_list\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_comment_id_list(html_soup):\n",
    "    comment_id_list = []\n",
    "    div_elements = html_soup.select('div')\n",
    "\n",
    "    for elem in div_elements:\n",
    "        comment_id = elem.get('comment_id')\n",
    "        if type(comment_id) == str:\n",
    "            comment_id_list.append(comment_id)\n",
    "    \n",
    "    return comment_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: comment_id\n",
    "return: comment_account_name, comment_text\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_comment_name_sentence(html_soup, comment_id):\n",
    "    div_comment = html_soup.find_all('div', {'comment_id': comment_id})\n",
    "    comment_account_name = div_comment[0].find('div', {'class': 'txt'}).text.split()[0]\n",
    "    comment_sentence = ''\n",
    "    if len(div_comment[0].find('div', {'class': 'txt'}).text.split()) == 3:\n",
    "        comment_sentence = div_comment[0].find('div', {'class': 'txt'}).text.split()[2]\n",
    "    elif len(div_comment[0].find('div', {'class': 'txt'}).text.split()) == 2:\n",
    "        comment_sentence = 'None or emoji'\n",
    "    return comment_account_name, comment_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup, mid\n",
    "return: account_link\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_account_link(html_soup, mid):\n",
    "    div_mid = html_soup.find_all('div', {'mid': mid})\n",
    "    time.sleep(1)\n",
    "    account_link = div_mid[0].find_all('a', {'class': 'name'})[0].get('href')\n",
    "    \n",
    "    return account_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: account_link\n",
    "return: html_soup\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_account_html_soup(driver, account_link):\n",
    "    retries = 3\n",
    "    i = 0\n",
    "    \n",
    "    while i < retries:\n",
    "        try:\n",
    "            driver.get(account_link)\n",
    "            time.sleep(7)  # 3sだとデータが取りきれない場合がある\n",
    "    \n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            return html_soup\n",
    "        \n",
    "        except TimeoutException:\n",
    "            i += 1\n",
    "            print('Timeout, Retrying... {} / {}'.format((i), retries))\n",
    "            continue\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_account_html_soup_newdriver(driver, account_link):\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "            \n",
    "        try:\n",
    "            driver.get(account_link)\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "            return driver, html_soup\n",
    "    \n",
    "        except:\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            driver = login(driver, account_link, 'account')  # ログイン\n",
    "            i += 1\n",
    "        i = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: rank, location, gender, follow, follower, weibo, get_time\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_account_info(html_soup):\n",
    "    rank = get_rank(html_soup)\n",
    "    location = get_location(html_soup)\n",
    "    gender = get_gender(html_soup)\n",
    "    follow, follower, weibo = get_follow_follower_weibo(html_soup)\n",
    "    get_time = get_now_time()\n",
    "    \n",
    "    return rank, location, gender, follow, follower, weibo, get_time\n",
    "\n",
    "\n",
    "def failed_account_info():\n",
    "    rank = 'None'\n",
    "    location = 'None'\n",
    "    gender = 'None'\n",
    "    follow = 'None'\n",
    "    follower = 'None'\n",
    "    weibo = 'None'\n",
    "    get_time = 'None'\n",
    "    return rank, location, gender, follow, follower, weibo, get_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_Soup\n",
    "return: rank\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_rank(html_soup):\n",
    "    span_all = html_soup.find_all('span')\n",
    "\n",
    "    rank = ''\n",
    "\n",
    "    for span_tag in span_all:\n",
    "        if \"Lv\" in span_tag.text:\n",
    "            rank = span_tag.text\n",
    "        \n",
    "    if rank == '':\n",
    "        rank = 'no rank'\n",
    "        \n",
    "    return rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: location\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_location(html_soup):\n",
    "    if html_soup.find_all('em', {'class': 'W_ficon ficon_cd_place S_ficon'}):\n",
    "        span = html_soup.find_all('span', {'class': 'item_text W_fl'})\n",
    "\n",
    "        location = ''\n",
    "\n",
    "        for tag in span:\n",
    "            if 'Lv' in tag.text:\n",
    "                location = span[1].text.split()\n",
    "                break\n",
    "            else:\n",
    "                location = span[0].text.split()\n",
    "\n",
    "        if type(location) == list:\n",
    "            word_concat = ''\n",
    "            for word in location:\n",
    "                word_concat += word\n",
    "            location = word_concat\n",
    "    else:\n",
    "        location = 'no location'\n",
    "        \n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: gender\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_gender(html_soup):\n",
    "\n",
    "    if html_soup.find_all('i', {'class': 'W_icon icon_pf_male'}):\n",
    "        gender = 'male'\n",
    "    elif html_soup.find_all('i', {'class': 'W_icon icon_pf_female'}):\n",
    "        gender = 'female'\n",
    "    else:\n",
    "        gender = 'no gender'\n",
    "        \n",
    "    return gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: follow, follower, weibo\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_follow_follower_weibo(html_soup):\n",
    "    if html_soup.find_all('strong'):\n",
    "        strongs = html_soup.find_all('strong')\n",
    "        try:\n",
    "            follow = strongs[0].text\n",
    "        except:\n",
    "            follow = 'no follow'\n",
    "        \n",
    "        try:\n",
    "            follower = strongs[1].text\n",
    "        except:\n",
    "            follower = 'no follower'\n",
    "        \n",
    "        try:\n",
    "            weibo = strongs[2].text\n",
    "        except:\n",
    "            weibo = 'no weibo'\n",
    "    else:\n",
    "        follow = 'no follow'\n",
    "        follower = 'no follower'\n",
    "        weibo = 'no weibo'\n",
    "        \n",
    "    return follow, follower, weibo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: None\n",
    "return: now_time\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_now_time():\n",
    "    now = dt.strftime(dt.now(), '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    return now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: None\n",
    "return: driver\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def set_driver():\n",
    "    options = Options()\n",
    "\n",
    "    # options.set_headless(True)\n",
    "    options.binary_location = \"/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary\"\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    chromedriver_path = \"/Users/higashi/Desktop/Document/chromedriver/chromedriver\"\n",
    "\n",
    "    return webdriver.Chrome(options=options, executable_path=chromedriver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: url\n",
    "return: urls\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_feed_links(start_url):\n",
    "    urls = []\n",
    "    urls.append(start_url)\n",
    "    \n",
    "    url = start_url\n",
    "    \n",
    "    for i in range(50):  # 何ページ目まで読むか\n",
    "        r = requests.get(url)\n",
    "        html_contents = r.text\n",
    "\n",
    "        html_soup = BeautifulSoup(html_contents)\n",
    "        try:\n",
    "            next_link = 'https://s.weibo.com' + html_soup.find_all('a', {'class': 'next'})[0].get('href')\n",
    "            if next_link in urls:\n",
    "                break\n",
    "            else:\n",
    "                urls.append(next_link)\n",
    "                url = next_link\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: driver\n",
    "return: elems, elems_suda_data\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_comment_button_list(driver, url):\n",
    "    elems = []\n",
    "    elems_suda_data = []\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "            \n",
    "        try:\n",
    "            element = driver.find_elements_by_tag_name('a')\n",
    "            for elem in element:\n",
    "                try:\n",
    "                    val_string = elem.get_attribute('action-type')\n",
    "                    if val_string == 'feed_list_comment':\n",
    "                        elems.append(elem)\n",
    "                        elems_suda_data.append(elem.get_attribute('suda-data'))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            return driver, elems, elems_suda_data\n",
    "        \n",
    "        except:\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            driver = login(driver, url, 'feed')  # ログイン\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: suda_data, elems, elems_suda_data\n",
    "return: None\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def click_comment(suda_data, elems, elems_suda_data):\n",
    "    try:\n",
    "        for i, elem in enumerate(elems):\n",
    "            if suda_data == elems_suda_data[i]:\n",
    "                element = elem\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        element.click()\n",
    "        time.sleep(5)  # 2s程度待たないとcomment欄が表示されない(javascript実行時間)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(driver, url, url_type):\n",
    "    i = 0\n",
    "    feed_login_xpath = '//*[@id=\"weibo_top_public\"]/div/div/div[3]/div[2]/ul/li[3]/a'\n",
    "    account_login_xpath = '//*[@id=\"pl_common_top\"]/div/div/div[3]/div[2]/ul/li[3]/a'\n",
    "    \n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "        \n",
    "        try:  # timeout対策\n",
    "            driver.get(url)\n",
    "            time.sleep(10)\n",
    "            try:\n",
    "                if url_type == 'feed':\n",
    "                    login_link = driver.find_element_by_xpath(feed_login_xpath)\n",
    "                    login_link.click()\n",
    "                    print('clicked login')\n",
    "                elif url_type == 'account':\n",
    "                    login_link = driver.find_element_by_xpath(account_login_xpath)\n",
    "                    login_link.click()\n",
    "                    print('clicked login')\n",
    "            except:\n",
    "                print(\"login xpath wasn't detected\")\n",
    "                raise TimeoutException\n",
    "                \n",
    "            time.sleep(5)\n",
    "            \n",
    "            try:\n",
    "                element = driver.find_elements_by_tag_name('input')\n",
    "                for elem in element:\n",
    "                    try:\n",
    "                        val_string = elem.get_attribute('node-type')\n",
    "                        if val_string == 'username':\n",
    "                            id_input = elem\n",
    "                            id_input.send_keys('pomtaro0509@gmail.com')\n",
    "                            print('id ok')\n",
    "                        elif val_string == 'password':\n",
    "                            pass_input = elem\n",
    "                            pass_input.send_keys('poMtar03')\n",
    "                            print('pass ok')\n",
    "                    except:\n",
    "                        print('continue')\n",
    "                        continue\n",
    "    \n",
    "                element = driver.find_elements_by_tag_name('a')\n",
    "                for elem in element:\n",
    "                    try:\n",
    "                        val_string = elem.get_attribute('node-type')\n",
    "                        if val_string == 'submitBtn':\n",
    "                            login_button = elem\n",
    "                            login_button.click()\n",
    "                            print('login ok')\n",
    "                            time.sleep(5)\n",
    "                            \n",
    "                            return driver  # ログイン完了後のdriverを出力\n",
    "                    except:\n",
    "                        print('continue')\n",
    "                        continue\n",
    "            except:\n",
    "                print('reboot browser')\n",
    "                raise TimeoutException\n",
    "        except TimeoutException:  # timeout対策\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id ok\npass ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting feed links is done.\n37 links are detected.\nprogress... : 1 / 37 feed link\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting feed html_soup is done.\ngetting mid_list is done.\n21 mids are detected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 1 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4345715628865730']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 2 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4346985915391341', '4346672815305657', '4346240781509927', '4346188633376624', '4346166588274320', '4346131372060556', '4346128293582017', '4346104503700986', '4346102038072801', '4346096610928726']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 3 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 4 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4348059322386584', '4348058579710831']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 5 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 6 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 7 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4348037172277810']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 8 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4348080042285370', '4348075168395624', '4348074832727543', '4348070214647723', '4348065525452163', '4348064354930431', '4348060634507188', '4348053513059403']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 9 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 10 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 11 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4348072454895082', '4348072307725897', '4348071942872928', '4348071909209133', '4348071804445192', '4348071766570137', '4348071737836183', '4348071694904349', '4348051566840893', '4348029928894960']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 12 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 13 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 14 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 15 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 16 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 17 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 18 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 19 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 20 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4347525417177258', '4347515568540995', '4347348857713845']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 21 / 21 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\nprogress... : 2 / 37 feed link\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting feed html_soup is done.\ngetting mid_list is done.\n20 mids are detected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 1 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4347285376706677']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 2 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4347305274873457', '4347273909338630', '4347253164961410', '4347240564592184']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 3 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 4 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4347201531955056', '4347193970212038', '4347163934904039', '4347160533372806']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 5 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 6 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4347036876968319']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 7 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 8 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 9 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 10 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 11 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 12 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 13 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 14 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 15 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 16 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 17 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 18 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4346950310624169', '4346564375857970']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    progress... : 19 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n    progress... : 20 / 20 mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account_link is done.\n    getting feed info is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n['4347187829480567', '4346982292074078', '4346700808625936', '4346574702196343', '4346565298385510', '4346552107720807']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    getting account html_soup is done.\n    getting account info is done.\n    storing data is done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5cb67193afec>\u001b[0m in \u001b[0;36mget_account_html_soup_newdriver\u001b[0;34m(driver, account_link)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WeiboScraping/venv/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WeiboScraping/venv/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WeiboScraping/venv/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: timeout\n  (Session info: chrome=75.0.3730.0)\n  (Driver info: chromedriver=2.44.609545 (c2f88692e98ce7233d2df7c724465ecacfe74df5),platform=Mac OS X 10.14.1 x86_64)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-134735201e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# アカウント詳細のhtmlを取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccount_html_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_account_html_soup_newdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccount_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'    getting account html_soup is done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-5cb67193afec>\u001b[0m in \u001b[0;36mget_account_html_soup_newdriver\u001b[0;34m(driver, account_link)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_page_load_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccount_link\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'account'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ログイン\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-27007f3b6d02>\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(driver, url, url_type)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# timeout対策\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0murl_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'feed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"\n",
    "テスト\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# スタートリンクの設定\n",
    "start_url = 'https://s.weibo.com/weibo?q=toyota&wvr=6&b=1&display=0&retcode=6102&Refer=SWeibo_box'\n",
    "\n",
    "# driver初期化\n",
    "timeout = 15\n",
    "driver = set_driver()\n",
    "driver.set_page_load_timeout(timeout)\n",
    "\n",
    "# ログイン\n",
    "driver = login(driver, start_url, 'feed')\n",
    "\n",
    "# フィードデータ用リスト\n",
    "account_names = []\n",
    "feed_times = []\n",
    "sentences = []\n",
    "shares = []\n",
    "comments = []\n",
    "goods = []\n",
    "ranks = []\n",
    "locations = []\n",
    "genders = []\n",
    "follows = []\n",
    "followers = []\n",
    "weiboes = []\n",
    "get_times = []\n",
    "types = []\n",
    "mids = []\n",
    "\n",
    "# コメントデータ用リスト\n",
    "comment_account_names = []\n",
    "comment_sentences = []\n",
    "comment_types = []\n",
    "comment_locations = []\n",
    "comment_genders = []\n",
    "comment_ranks = []\n",
    "comment_follows = []\n",
    "comment_followers = []\n",
    "comment_weiboes = []\n",
    "comment_post_times = []\n",
    "comment_get_times = []\n",
    "comment_shares = []\n",
    "comment_comments = []\n",
    "comment_goods = []\n",
    "comment_mids = []\n",
    "\n",
    "# プログラム内保持データリスト\n",
    "account_links = []\n",
    "\n",
    "# フィードのリンクを全て取得\n",
    "feed_links = get_feed_links(start_url)\n",
    "print('getting feed links is done.')\n",
    "print('{} links are detected.'.format(len(feed_links)))\n",
    "\n",
    "# フィードページごとにデータ取得\n",
    "for i, feed_link in enumerate(feed_links):\n",
    "    print('progress... : {} / {} feed link'.format((i+1), len(feed_links)))\n",
    "    # フィードのhtmlを取得\n",
    "    driver, feed_html_soup = get_feed_html_soup_newdriver(driver, feed_link)\n",
    "    print('getting feed html_soup is done.')\n",
    "    \n",
    "    if feed_html_soup:\n",
    "        # midリストを取得\n",
    "        mid_list = get_mid_list(feed_html_soup)\n",
    "        print('getting mid_list is done.')\n",
    "        print('{} mids are detected.'.format(len(mid_list)))\n",
    "        \n",
    "        # commentボタンリストを取得\n",
    "        driver, elems, elems_suda_data = get_comment_button_list(driver, feed_link)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # 初期化\n",
    "    account_links.clear()\n",
    "        \n",
    "    # commentデータを先に取得\n",
    "    for j, mid in enumerate(mid_list):\n",
    "        # 進捗表示\n",
    "        print('    progress... : {} / {} mid'.format((j+1), len(mid_list)))\n",
    "        \n",
    "        # アカウントリンクを取得\n",
    "        account_link = 'https:' + get_account_link(feed_html_soup, mid)\n",
    "        account_links.append(account_link)\n",
    "        print('    getting account_link is done.')\n",
    "               \n",
    "        # フィードデータを取得\n",
    "        account_name, feed_time, sentence, share, comment, suda_data, good = get_feed_info(feed_html_soup, mid)\n",
    "        print('    getting feed info is done')\n",
    "        \n",
    "        # コメントが存在する場合、コメントを取得しに行く\n",
    "        if comment != '0' and elems is not None and elems_suda_data is not None:\n",
    "            click_comment(suda_data, elems, elems_suda_data)\n",
    "            print(\"clicked\")\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "            comment_id_list = get_comment_id_list(html_soup)\n",
    "            print(comment_id_list)\n",
    "            click_comment(suda_data, elems, elems_suda_data)  # コメント欄を閉じておく\n",
    "            \n",
    "            # 宣言\n",
    "            global comment_account_names, comment_sentences, comment_types, comment_locations\n",
    "            global comment_genders, comment_ranks, comment_follows, comment_followers\n",
    "            global comment_weiboes, comment_post_times, comment_get_times, comment_shares\n",
    "            global comment_comments, comment_goods, comment_mids\n",
    "            mid = mid\n",
    "            \n",
    "            # コメントデータを格納\n",
    "            for comment_id in comment_id_list:\n",
    "                comment_account_name, comment_sentence = get_comment_name_sentence(html_soup, comment_id)\n",
    "                comment_account_names.append(comment_account_name)\n",
    "                comment_sentences.append(comment_sentence)\n",
    "                comment_types.append('comment')\n",
    "                # コメントについては、下記情報は一旦保留\n",
    "                comment_locations.append('None')\n",
    "                comment_genders.append('None')\n",
    "                comment_ranks.append('None')\n",
    "                comment_follows.append('None')\n",
    "                comment_followers.append('None')\n",
    "                comment_weiboes.append('None')\n",
    "                comment_post_times.append('None')\n",
    "                comment_get_times.append('None')\n",
    "                comment_shares.append('None')\n",
    "                comment_comments.append('None')\n",
    "                comment_goods.append('None')\n",
    "                comment_mids.append(mid)\n",
    "        \n",
    "        # フィードデータの一部を格納\n",
    "        account_names.append(account_name)\n",
    "        feed_times.append(feed_time)\n",
    "        sentences.append(sentence)\n",
    "        shares.append(share)\n",
    "        comments.append(comment)\n",
    "        goods.append(good)\n",
    "        mids.append(mid)\n",
    "    \n",
    "    # アカウント情報を取得\n",
    "    for k, account_link in enumerate(account_links):\n",
    "        \n",
    "        # アカウント詳細のhtmlを取得\n",
    "        driver, account_html_soup = get_account_html_soup_newdriver(driver, account_link)\n",
    "        print('    getting account html_soup is done.')\n",
    "        \n",
    "        # アカウントデータを取得\n",
    "        if account_html_soup:\n",
    "            rank, location, gender, follow, follower, weibo, get_time = get_account_info(account_html_soup)\n",
    "            print('    getting account info is done.')\n",
    "        else:\n",
    "            rank, location, gender, follow, follower, weibo, get_time = failed_account_info()  # 取得できなかった時の穴埋め\n",
    "            continue\n",
    "            \n",
    "        # タイプを定義\n",
    "        type_name = 'feed'\n",
    "        \n",
    "        # フィードデータ格納\n",
    "        ranks.append(rank)\n",
    "        locations.append(location)\n",
    "        genders.append(gender)\n",
    "        follows.append(follow)\n",
    "        followers.append(follower)\n",
    "        weiboes.append(weibo)\n",
    "        get_times.append(get_time)\n",
    "        types.append(type_name)\n",
    "        \n",
    "        print('    storing data is done')\n",
    "        \n",
    "# csv保存\n",
    "os.chdir('/Users/higashi/PycharmProjects/WeiboScraping/venv/data')\n",
    "\n",
    "print('-*-    -*-    -*-')\n",
    "print('account_names : ', len(account_names))\n",
    "print('locations : ', len(locations))\n",
    "print('genders : ', len(genders))\n",
    "print('ranks : ', len(ranks))\n",
    "print('follows : ', len(follows))\n",
    "print('followers : ', len(followers))\n",
    "print('weiboes : ', len(weiboes))\n",
    "print('feed_times : ', len(feed_times))\n",
    "print('get_times : ', len(get_times))\n",
    "print('type : ', len(types))\n",
    "print('sentences : ', len(sentences))\n",
    "print('mids : ', len(mids))\n",
    "print('shares : ', len(shares))\n",
    "print('comments : ', len(comments))\n",
    "print('goods : ', len(goods))\n",
    "print('-*-    -*-    -*-')\n",
    "\n",
    "df_feed = pd.DataFrame({\n",
    "    'Account': account_names,\n",
    "    'Location': locations,\n",
    "    'Gender': genders,\n",
    "    'Rank': ranks,\n",
    "    'Follow': follows,\n",
    "    'Follower': followers,\n",
    "    'Weibo': weiboes,\n",
    "    'FeedTime': feed_times,\n",
    "    'GetTime': get_times,\n",
    "    'Type': types,\n",
    "    'Sentence': sentences,\n",
    "    'Mid': mids,\n",
    "    'Share': shares,\n",
    "    'Comment': comments,\n",
    "    'Good': goods\n",
    "})\n",
    "\n",
    "df_comment = pd.DataFrame({\n",
    "    'Account': comment_account_names,\n",
    "    'Location': comment_locations,\n",
    "    'Gender': comment_genders,\n",
    "    'Rank': comment_ranks,\n",
    "    'Follow': comment_follows,\n",
    "    'Follower': comment_followers,\n",
    "    'Weibo': comment_weiboes,\n",
    "    'FeedTime': comment_post_times,\n",
    "    'GetTime': comment_get_times,\n",
    "    'Type': comment_types,\n",
    "    'Sentence': comment_sentences,\n",
    "    'ParentMid': comment_mids,\n",
    "    'Share': comment_shares,\n",
    "    'Comment': comment_comments,\n",
    "    'Good': comment_goods\n",
    "})\n",
    "\n",
    "df_feed.to_csv('data_feed_tmp' + '.csv')\n",
    "df_comment.to_csv('data_comment_tmp' + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/higashi/PycharmProjects/WeiboScraping/venv/data')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Account': account_names,\n",
    "    'Location': locations,\n",
    "    'Gender': genders,\n",
    "    'Rank': ranks,\n",
    "    'Follow': follows,\n",
    "    'Follower': followers,\n",
    "    'Weibo': weiboes,\n",
    "    'FeedTime': feed_times,\n",
    "    'GetTime': get_times,\n",
    "    'Type': types,\n",
    "    'Sentence': sentences,\n",
    "    'Share': shares,\n",
    "    'Comment': comments,\n",
    "    'Good': goods\n",
    "})\n",
    "\n",
    "#df.to_csv('data_tmp' + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_names :  215\nfeed_times :  215\nsentences :  215\nshares :  215\ncomments :  215\ngoods :  215\nmids 215\n-*-    -*-    -*-\nlocations :  215\ngenders :  215\nranks :  215\nfollows :  215\nfollowers :  215\nweiboes :  215\nget_times :  215\n-*-    -*-    -*-\ncomment_shares :  224\ncomment_comments :  224\ncomment_goods 224\n"
     ]
    }
   ],
   "source": [
    "print('account_names : ', len(account_names))\n",
    "print('feed_times : ', len(feed_times))\n",
    "print('sentences : ', len(sentences))\n",
    "print('shares : ', len(shares))\n",
    "print('comments : ', len(comments))\n",
    "print('goods : ', len(goods))\n",
    "print('mids', len(mids))\n",
    "\n",
    "print('-*-    -*-    -*-')\n",
    "\n",
    "print('locations : ', len(locations))\n",
    "print('genders : ', len(genders))\n",
    "print('ranks : ', len(ranks))\n",
    "print('follows : ', len(follows))\n",
    "print('followers : ', len(followers))\n",
    "print('weiboes : ', len(weiboes))\n",
    "print('get_times : ', len(get_times))\n",
    "\n",
    "print('-*-    -*-    -*-')\n",
    "\n",
    "print('comment_shares : ', len(comment_shares))\n",
    "print('comment_comments : ', len(comment_comments))\n",
    "print('comment_goods', len(comment_goods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35', '6', '1', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0', '5', '1', '4', '0', '0', '1', '0', '0', '0', '0', '0', '3', '0', '0', '0', '0', '6', '0', '2', '0']\n"
     ]
    }
   ],
   "source": [
    "print(comments)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'https://s.weibo.com/weibo/%25E7%25A4%25BE%25E4%25BC%259A?topnav=1&wvr=6&b=1&display=0&retcode=6102'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = set_driver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = 2\n",
    "driver.set_page_load_timeout(timeout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_soup = get_feed_html_soup_newdriver(driver, start_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    try:\n",
    "        a = 1/0\n",
    "        print('a', a)\n",
    "    except:\n",
    "        b = 1/0\n",
    "        print('b', b)\n",
    "    try:\n",
    "        c = 1/0\n",
    "        print(c)\n",
    "    except:\n",
    "        d = 1/0\n",
    "        print(d)\n",
    "except:\n",
    "    print('error')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
