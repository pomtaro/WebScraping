{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime as dt\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: url\n",
    "return: html\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_feed_html_soup(driver, url):\n",
    "    retries = 3\n",
    "    i = 0\n",
    "    \n",
    "    while i < retries:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            return html_soup\n",
    "        except TimeoutException:\n",
    "            i += 1\n",
    "            print('Timeout, Retrying... {} / {}'.format((i), retries))\n",
    "            driver.refresh()\n",
    "            print('driver was refreshed')\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_feed_html_soup_newdriver(driver, url):\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "            return driver, html_soup\n",
    "    \n",
    "        except TimeoutException:\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            driver = login(driver, url, 'feed')  # ログイン\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: mid_list\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_mid_list(html_soup):\n",
    "    mid_list = []\n",
    "    div_elements = html_soup.find_all('div', {'id': 'pl_feedlist_index'})\n",
    "    div_elements = div_elements[0].find_all('div', {'class': 'card-wrap'})\n",
    "    for elem in div_elements:\n",
    "        mid = elem.get('mid')\n",
    "        if type(mid) == str:\n",
    "            mid_list.append(mid)\n",
    "    \n",
    "    return mid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: mid\n",
    "return: account_name, feed_time, sentence, share, comment, good\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_feed_info(html_soup, mid):\n",
    "    div_mid = html_soup.find_all('div', {'mid': mid})\n",
    "    \n",
    "    # アカウント名\n",
    "    account_name = div_mid[0].find('p').get('nick-name')\n",
    "    \n",
    "    # 時刻\n",
    "    feed_time = ''.join(div_mid[0].find_all('p', {'class': 'from'})[0].find('a').text.split())\n",
    "    try:\n",
    "        if '今天' in feed_time:     \n",
    "            feed_time = dt.strftime(dt.now(), '%Y-%m-%d ') + feed_time.split('今天')[1] + ':00'\n",
    "        elif '前' in feed_time:\n",
    "            feed_time = dt.strftime(dt.now(), '%Y-%m-%d %H:%M:%S')\n",
    "        elif '秒' in feed_time:\n",
    "            feed_time = dt.strftime(dt.now(), '%Y-%m-%d %H:%M:%S')\n",
    "        elif len(feed_time) < 12:\n",
    "            feed_time = dt.strptime(feed_time, '%m月%d日%H:%M').replace(year=2019)\n",
    "        else:\n",
    "            feed_time = dt.strptime(feed_time, '%Y年%m月%d日%H:%M')\n",
    "    except:\n",
    "        feed_time = 'not detected'\n",
    "    # 本文\n",
    "    sentence = ''.join(div_mid[0].find('p').text.split())\n",
    "    \n",
    "    # シェア、コメント、いいね\n",
    "    share = ''\n",
    "    comment = ''\n",
    "    suda_data = ''\n",
    "    good = ''\n",
    "    bottom_items = div_mid[0].find_all('div', {'class': 'card-act'})[0].find_all('li')\n",
    "    for bottom_item in bottom_items:\n",
    "        \n",
    "        if bottom_item.text == '收藏':\n",
    "            pass\n",
    "        elif '转发' in bottom_item.text:\n",
    "            if len(bottom_item.text.split()) < 2:\n",
    "                share = '0'\n",
    "            else:\n",
    "                share = bottom_item.text.split()[1]\n",
    "        elif '评论' in bottom_item.text:\n",
    "            if len(bottom_item.text.split()) < 2:\n",
    "                comment = '0'\n",
    "            else:\n",
    "                comment = bottom_item.text.split()[1]\n",
    "                suda_data = bottom_item.find_all('a')[0].get('suda-data')\n",
    "        else:\n",
    "            if len(bottom_item.text.split()) < 1:\n",
    "                good = '0'\n",
    "            else:\n",
    "                good = bottom_item.text   \n",
    "    \n",
    "    return account_name, feed_time, sentence, share, comment, suda_data, good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: comment_id_list\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_comment_id_list(html_soup):\n",
    "    comment_id_list = []\n",
    "    div_elements = html_soup.select('div')\n",
    "\n",
    "    for elem in div_elements:\n",
    "        comment_id = elem.get('comment_id')\n",
    "        if type(comment_id) == str:\n",
    "            comment_id_list.append(comment_id)\n",
    "    \n",
    "    return comment_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: comment_id\n",
    "return: comment_account_name, comment_text\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_comment_name_sentence(html_soup, comment_id):\n",
    "    div_comment = html_soup.find_all('div', {'comment_id': comment_id})\n",
    "    comment_account_name = div_comment[0].find('div', {'class': 'txt'}).text.split()[0]\n",
    "    comment_sentence = ''\n",
    "    if len(div_comment[0].find('div', {'class': 'txt'}).text.split()) == 3:\n",
    "        comment_sentence = div_comment[0].find('div', {'class': 'txt'}).text.split()[2]\n",
    "    elif len(div_comment[0].find('div', {'class': 'txt'}).text.split()) == 2:\n",
    "        comment_sentence = 'None or emoji'\n",
    "    return comment_account_name, comment_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup, mid\n",
    "return: account_link\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_account_link(html_soup, mid):\n",
    "    div_mid = html_soup.find_all('div', {'mid': mid})\n",
    "    time.sleep(1)\n",
    "    account_link = div_mid[0].find_all('a', {'class': 'name'})[0].get('href')\n",
    "    \n",
    "    return account_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: account_link\n",
    "return: html_soup\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_account_html_soup(driver, account_link):\n",
    "    retries = 3\n",
    "    i = 0\n",
    "    \n",
    "    while i < retries:\n",
    "        try:\n",
    "            driver.get(account_link)\n",
    "            time.sleep(7)  # 3sだとデータが取りきれない場合がある\n",
    "    \n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            return html_soup\n",
    "        \n",
    "        except TimeoutException:\n",
    "            i += 1\n",
    "            print('Timeout, Retrying... {} / {}'.format((i), retries))\n",
    "            continue\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_account_html_soup_newdriver(driver, account_link):\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "            \n",
    "        try:\n",
    "            driver.get(account_link)\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "            return driver, html_soup\n",
    "    \n",
    "        except:\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            driver = login(driver, account_link, 'account')  # ログイン\n",
    "            i += 1\n",
    "        i = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: rank, location, gender, follow, follower, weibo, get_time\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_account_info(html_soup):\n",
    "    rank = get_rank(html_soup)\n",
    "    location = get_location(html_soup)\n",
    "    gender = get_gender(html_soup)\n",
    "    follow, follower, weibo = get_follow_follower_weibo(html_soup)\n",
    "    get_time = get_now_time()\n",
    "    \n",
    "    return rank, location, gender, follow, follower, weibo, get_time\n",
    "\n",
    "\n",
    "def failed_account_info():\n",
    "    rank = 'None'\n",
    "    location = 'None'\n",
    "    gender = 'None'\n",
    "    follow = 'None'\n",
    "    follower = 'None'\n",
    "    weibo = 'None'\n",
    "    get_time = 'None'\n",
    "    return rank, location, gender, follow, follower, weibo, get_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_Soup\n",
    "return: rank\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_rank(html_soup):\n",
    "    span_all = html_soup.find_all('span')\n",
    "\n",
    "    rank = ''\n",
    "\n",
    "    for span_tag in span_all:\n",
    "        if \"Lv\" in span_tag.text:\n",
    "            rank = span_tag.text\n",
    "        \n",
    "    if rank == '':\n",
    "        rank = 'no rank'\n",
    "        \n",
    "    return rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: location\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_location(html_soup):\n",
    "    if html_soup.find_all('em', {'class': 'W_ficon ficon_cd_place S_ficon'}):\n",
    "        span = html_soup.find_all('span', {'class': 'item_text W_fl'})\n",
    "\n",
    "        location = ''\n",
    "\n",
    "        for tag in span:\n",
    "            if 'Lv' in tag.text:\n",
    "                location = span[1].text.split()\n",
    "                break\n",
    "            else:\n",
    "                location = span[0].text.split()\n",
    "\n",
    "        if type(location) == list:\n",
    "            word_concat = ''\n",
    "            for word in location:\n",
    "                word_concat += word\n",
    "            location = word_concat\n",
    "    else:\n",
    "        location = 'no location'\n",
    "        \n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: gender\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_gender(html_soup):\n",
    "\n",
    "    if html_soup.find_all('i', {'class': 'W_icon icon_pf_male'}):\n",
    "        gender = 'male'\n",
    "    elif html_soup.find_all('i', {'class': 'W_icon icon_pf_female'}):\n",
    "        gender = 'female'\n",
    "    else:\n",
    "        gender = 'no gender'\n",
    "        \n",
    "    return gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: html_soup\n",
    "return: follow, follower, weibo\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_follow_follower_weibo(html_soup):\n",
    "    if html_soup.find_all('strong'):\n",
    "        strongs = html_soup.find_all('strong')\n",
    "        try:\n",
    "            follow = strongs[0].text\n",
    "        except:\n",
    "            follow = 'no follow'\n",
    "        \n",
    "        try:\n",
    "            follower = strongs[1].text\n",
    "        except:\n",
    "            follower = 'no follower'\n",
    "        \n",
    "        try:\n",
    "            weibo = strongs[2].text\n",
    "        except:\n",
    "            weibo = 'no weibo'\n",
    "    else:\n",
    "        follow = 'no follow'\n",
    "        follower = 'no follower'\n",
    "        weibo = 'no weibo'\n",
    "        \n",
    "    return follow, follower, weibo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: None\n",
    "return: now_time\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_now_time():\n",
    "    now = dt.strftime(dt.now(), '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    return now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: None\n",
    "return: driver\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def set_driver():\n",
    "    options = Options()\n",
    "\n",
    "    # options.set_headless(True)\n",
    "    options.binary_location = \"/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary\"\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    chromedriver_path = \"/Users/higashi/Desktop/Document/chromedriver/chromedriver\"\n",
    "\n",
    "    return webdriver.Chrome(options=options, executable_path=chromedriver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: url\n",
    "return: urls\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_feed_links(start_url):\n",
    "    urls = []\n",
    "    urls.append(start_url)\n",
    "    \n",
    "    url = start_url\n",
    "    \n",
    "    for i in range(200):  # 何ページ目まで読むか\n",
    "        r = requests.get(url)\n",
    "        html_contents = r.text\n",
    "\n",
    "        html_soup = BeautifulSoup(html_contents)\n",
    "        try:\n",
    "            next_link = 'https://s.weibo.com' + html_soup.find_all('a', {'class': 'next'})[0].get('href')\n",
    "            if next_link in urls:\n",
    "                continue\n",
    "            else:\n",
    "                urls.append(next_link)\n",
    "                url = next_link\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: driver\n",
    "return: elems, elems_suda_data\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_comment_button_list(driver, url):\n",
    "    elems = []\n",
    "    elems_suda_data = []\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "            \n",
    "        try:\n",
    "            element = driver.find_elements_by_tag_name('a')\n",
    "            for elem in element:\n",
    "                try:\n",
    "                    val_string = elem.get_attribute('action-type')\n",
    "                    if val_string == 'feed_list_comment':\n",
    "                        elems.append(elem)\n",
    "                        elems_suda_data.append(elem.get_attribute('suda-data'))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            return driver, elems, elems_suda_data\n",
    "        \n",
    "        except:\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            driver = login(driver, url, 'feed')  # ログイン\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg: suda_data, elems, elems_suda_data\n",
    "return: None\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def click_comment(suda_data, elems, elems_suda_data):\n",
    "    try:\n",
    "        for i, elem in enumerate(elems):\n",
    "            if suda_data == elems_suda_data[i]:\n",
    "                element = elem\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        element.click()\n",
    "        time.sleep(5)  # 2s程度待たないとcomment欄が表示されない(javascript実行時間)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(driver, url, url_type):\n",
    "    i = 0\n",
    "    feed_login_xpath = '//*[@id=\"weibo_top_public\"]/div/div/div[3]/div[2]/ul/li[3]/a'\n",
    "    account_login_xpath = '//*[@id=\"pl_common_top\"]/div/div/div[3]/div[2]/ul/li[3]/a'\n",
    "    \n",
    "    while True:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            driver = driver\n",
    "        \n",
    "        try:  # timeout対策\n",
    "            driver.get(url)\n",
    "            time.sleep(10)\n",
    "            try:\n",
    "                if url_type == 'feed':\n",
    "                    login_link = driver.find_element_by_xpath(feed_login_xpath)\n",
    "                    login_link.click()\n",
    "                    print('clicked login')\n",
    "                elif url_type == 'account':\n",
    "                    login_link = driver.find_element_by_xpath(account_login_xpath)\n",
    "                    login_link.click()\n",
    "                    print('clicked login')\n",
    "            except:\n",
    "                print(\"login xpath wasn't detected\")\n",
    "                raise TimeoutException\n",
    "                \n",
    "            time.sleep(5)\n",
    "            \n",
    "            try:\n",
    "                element = driver.find_elements_by_tag_name('input')\n",
    "                for elem in element:\n",
    "                    try:\n",
    "                        val_string = elem.get_attribute('node-type')\n",
    "                        if val_string == 'username':\n",
    "                            id_input = elem\n",
    "                            id_input.send_keys('pomtaro0509@gmail.com')\n",
    "                            print('id ok')\n",
    "                        elif val_string == 'password':\n",
    "                            pass_input = elem\n",
    "                            pass_input.send_keys('poMtar03')\n",
    "                            print('pass ok')\n",
    "                    except:\n",
    "                        print('continue')\n",
    "                        continue\n",
    "    \n",
    "                element = driver.find_elements_by_tag_name('a')\n",
    "                for elem in element:\n",
    "                    try:\n",
    "                        val_string = elem.get_attribute('node-type')\n",
    "                        if val_string == 'submitBtn':\n",
    "                            login_button = elem\n",
    "                            login_button.click()\n",
    "                            print('login ok')\n",
    "                            time.sleep(5)\n",
    "                            \n",
    "                            return driver  # ログイン完了後のdriverを出力\n",
    "                    except:\n",
    "                        print('continue')\n",
    "                        continue\n",
    "            except:\n",
    "                print('reboot browser')\n",
    "                raise TimeoutException\n",
    "        except TimeoutException:  # timeout対策\n",
    "            driver.quit()\n",
    "            driver = set_driver()\n",
    "            timeout = 10\n",
    "            driver.set_page_load_timeout(timeout)\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4af4f55e1685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# ログイン\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# フィードのリンクを全て取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-27007f3b6d02>\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(driver, url, url_type)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# timeout対策\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n\u001b[1;32m     71\u001b[0m                                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                                             **urlopen_kw)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     def request_encode_url(self, method, url, fields=None, headers=None,\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higashi/PycharmProjects/WebScraping/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"\n",
    "クローリング開始\n",
    "\"\"\"\n",
    "\n",
    "# フィードデータ用リスト\n",
    "account_names = []\n",
    "feed_times = []\n",
    "sentences = []\n",
    "shares = []\n",
    "comments = []\n",
    "goods = []\n",
    "ranks = []\n",
    "locations = []\n",
    "genders = []\n",
    "follows = []\n",
    "followers = []\n",
    "weiboes = []\n",
    "get_times = []\n",
    "types = []\n",
    "mids = []\n",
    "\n",
    "# コメントデータ用リスト\n",
    "comment_account_names = []\n",
    "comment_sentences = []\n",
    "comment_types = []\n",
    "comment_locations = []\n",
    "comment_genders = []\n",
    "comment_ranks = []\n",
    "comment_follows = []\n",
    "comment_followers = []\n",
    "comment_weiboes = []\n",
    "comment_post_times = []\n",
    "comment_get_times = []\n",
    "comment_shares = []\n",
    "comment_comments = []\n",
    "comment_goods = []\n",
    "comment_mids = []\n",
    "\n",
    "# プログラム内保持データリスト\n",
    "account_links = []\n",
    "\n",
    "# スタートリンクの定義\n",
    "start_url = 'https://s.weibo.com/weibo/d%2520program?topnav=1&wvr=6'\n",
    "\n",
    "# driver初期化\n",
    "timeout = 15\n",
    "driver = set_driver()\n",
    "driver.set_page_load_timeout(timeout)\n",
    "\n",
    "# ログイン\n",
    "driver = login(driver, start_url, 'feed')\n",
    "\n",
    "# フィードのリンクを全て取得\n",
    "feed_links = get_feed_links(start_url)\n",
    "print('getting feed links was done.')\n",
    "print('{} links were detected.'.format(len(feed_links)))\n",
    "\n",
    "# フィードページごとにデータ取得\n",
    "for i, feed_link in enumerate(feed_links):\n",
    "    print('--progress... : {} / {} feed link'.format((i+1), len(feed_links)))\n",
    "    # フィードのhtmlを取得\n",
    "    driver, feed_html_soup = get_feed_html_soup_newdriver(driver, feed_link)\n",
    "    print('--getting feed html_soup was done.')\n",
    "    \n",
    "    if feed_html_soup:\n",
    "        # midリストを取得\n",
    "        mid_list = get_mid_list(feed_html_soup)\n",
    "        print('--getting mid_list was done.')\n",
    "        print('--{} mids are detected.'.format(len(mid_list)))\n",
    "        \n",
    "        # commentボタンリストを取得\n",
    "        driver, elems, elems_suda_data = get_comment_button_list(driver, feed_link)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # 初期化\n",
    "    account_links.clear()\n",
    "        \n",
    "    # commentデータを先に取得\n",
    "    for j, mid in enumerate(mid_list):\n",
    "        # 進捗表示\n",
    "        print('----progress... : {} / {} mid, {} / {} feed link'.format((j+1), len(mid_list),\n",
    "                                                                        (i+1), len(feed_links)))\n",
    "        \n",
    "        # アカウントリンクを取得\n",
    "        account_link = 'https:' + get_account_link(feed_html_soup, mid)\n",
    "        account_links.append(account_link)\n",
    "        print('----getting account_link was done.')\n",
    "               \n",
    "        # フィードデータを取得\n",
    "        account_name, feed_time, sentence, share, comment, suda_data, good = get_feed_info(feed_html_soup, mid)\n",
    "        print('----getting feed info was done.')\n",
    "        \n",
    "        # コメントが存在する場合、コメントを取得しに行く\n",
    "        if comment != '0' and elems is not None and elems_suda_data is not None:\n",
    "            click_comment(suda_data, elems, elems_suda_data)\n",
    "            html = driver.page_source.encode('utf-8')\n",
    "            html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "            comment_id_list = get_comment_id_list(html_soup)\n",
    "            print('------{} comments were detected.'.format(len(comment_id_list)))\n",
    "            click_comment(suda_data, elems, elems_suda_data)  # コメント欄を閉じておく\n",
    "            \n",
    "            # 宣言\n",
    "            global comment_account_names, comment_sentences, comment_types, comment_locations\n",
    "            global comment_genders, comment_ranks, comment_follows, comment_followers\n",
    "            global comment_weiboes, comment_post_times, comment_get_times, comment_shares\n",
    "            global comment_comments, comment_goods, comment_mids\n",
    "            mid = mid\n",
    "            \n",
    "            # コメントデータを取得、格納\n",
    "            for comment_id in comment_id_list:\n",
    "                # データ取得\n",
    "                comment_account_name, comment_sentence = get_comment_name_sentence(html_soup, comment_id)\n",
    "                \n",
    "                # データ格納\n",
    "                comment_account_names.append(comment_account_name)\n",
    "                comment_sentences.append(comment_sentence)\n",
    "                comment_types.append('comment')\n",
    "                comment_locations.append('None')\n",
    "                comment_genders.append('None')\n",
    "                comment_ranks.append('None')\n",
    "                comment_follows.append('None')\n",
    "                comment_followers.append('None')\n",
    "                comment_weiboes.append('None')\n",
    "                comment_post_times.append('None')\n",
    "                comment_get_times.append('None')\n",
    "                comment_shares.append('None')\n",
    "                comment_comments.append('None')\n",
    "                comment_goods.append('None')\n",
    "                comment_mids.append(mid)\n",
    "            print('------getting comment data was done.')\n",
    "        \n",
    "        # フィードデータの一部を格納\n",
    "        account_names.append(account_name)\n",
    "        feed_times.append(feed_time)\n",
    "        sentences.append(sentence)\n",
    "        shares.append(share)\n",
    "        comments.append(comment)\n",
    "        goods.append(good)\n",
    "        mids.append(mid)\n",
    "        \n",
    "        print('----storing feed data was done.')\n",
    "    \n",
    "    # アカウント情報を取得\n",
    "    for k, account_link in enumerate(account_links):\n",
    "        # 進捗表示\n",
    "        print('----progress... : {} / {} account_link, {} / {} feed link'.format((k+1), len(account_links),\n",
    "                                                                                 (i+1), len(feed_links)))\n",
    "        \n",
    "        # アカウント詳細のhtmlを取得\n",
    "        driver, account_html_soup = get_account_html_soup_newdriver(driver, account_link)\n",
    "        print('----getting account html_soup was done.')\n",
    "        \n",
    "        # アカウントデータを取得\n",
    "        if account_html_soup:\n",
    "            rank, location, gender, follow, follower, weibo, get_time = get_account_info(account_html_soup)\n",
    "            print('----getting account info was done.')\n",
    "        else:\n",
    "            rank, location, gender, follow, follower, weibo, get_time = failed_account_info()\n",
    "            continue\n",
    "            \n",
    "        # タイプを定義\n",
    "        type_name = 'feed'\n",
    "        \n",
    "        # フィードデータ格納\n",
    "        ranks.append(rank)\n",
    "        locations.append(location)\n",
    "        genders.append(gender)\n",
    "        follows.append(follow)\n",
    "        followers.append(follower)\n",
    "        weiboes.append(weibo)\n",
    "        get_times.append(get_time)\n",
    "        types.append(type_name)\n",
    "        \n",
    "        print('----storing account data was done')\n",
    "        \n",
    "# csv保存\n",
    "os.chdir('/Users/higashi/PycharmProjects/Scraping/venv/weibo/data')\n",
    "\n",
    "print('-*-    -*-    -*-')\n",
    "print('account_names : ', len(account_names))\n",
    "print('locations : ', len(locations))\n",
    "print('genders : ', len(genders))\n",
    "print('ranks : ', len(ranks))\n",
    "print('follows : ', len(follows))\n",
    "print('followers : ', len(followers))\n",
    "print('weiboes : ', len(weiboes))\n",
    "print('feed_times : ', len(feed_times))\n",
    "print('get_times : ', len(get_times))\n",
    "print('type : ', len(types))\n",
    "print('sentences : ', len(sentences))\n",
    "print('mids : ', len(mids))\n",
    "print('shares : ', len(shares))\n",
    "print('comments : ', len(comments))\n",
    "print('goods : ', len(goods))\n",
    "print('-*-    -*-    -*-')\n",
    "\n",
    "df_feed = pd.DataFrame({\n",
    "    'Account': account_names,\n",
    "    'Location': locations,\n",
    "    'Gender': genders,\n",
    "    'Rank': ranks,\n",
    "    'Follow': follows,\n",
    "    'Follower': followers,\n",
    "    'Weibo': weiboes,\n",
    "    'FeedTime': feed_times,\n",
    "    'GetTime': get_times,\n",
    "    'Type': types,\n",
    "    'Sentence': sentences,\n",
    "    'Mid': mids,\n",
    "    'Share': shares,\n",
    "    'Comment': comments,\n",
    "    'Good': goods\n",
    "})\n",
    "\n",
    "df_comment = pd.DataFrame({\n",
    "    'Account': comment_account_names,\n",
    "    'Location': comment_locations,\n",
    "    'Gender': comment_genders,\n",
    "    'Rank': comment_ranks,\n",
    "    'Follow': comment_follows,\n",
    "    'Follower': comment_followers,\n",
    "    'Weibo': comment_weiboes,\n",
    "    'FeedTime': comment_post_times,\n",
    "    'GetTime': comment_get_times,\n",
    "    'Type': comment_types,\n",
    "    'Sentence': comment_sentences,\n",
    "    'ParentMid': comment_mids,\n",
    "    'Share': comment_shares,\n",
    "    'Comment': comment_comments,\n",
    "    'Good': comment_goods\n",
    "})\n",
    "\n",
    "df_feed.to_csv('data_feed_tmp' + '.csv')\n",
    "df_comment.to_csv('data_comment_tmp' + '.csv')\n",
    "\n",
    "print('crawling was completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_names :  421\nfeed_times :  421\nsentences :  421\nshares :  421\ncomments :  421\ngoods :  421\nmids 421\n-*-    -*-    -*-\nlocations :  421\ngenders :  421\nranks :  421\nfollows :  421\nfollowers :  421\nweiboes :  421\nget_times :  421\n-*-    -*-    -*-\ncomment_shares :  0\ncomment_comments :  0\ncomment_goods 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "データ数の確認\n",
    "\"\"\"\n",
    "\n",
    "print('account_names : ', len(account_names))\n",
    "print('feed_times : ', len(feed_times))\n",
    "print('sentences : ', len(sentences))\n",
    "print('shares : ', len(shares))\n",
    "print('comments : ', len(comments))\n",
    "print('goods : ', len(goods))\n",
    "print('mids', len(mids))\n",
    "\n",
    "print('-*-    -*-    -*-')\n",
    "\n",
    "print('locations : ', len(locations))\n",
    "print('genders : ', len(genders))\n",
    "print('ranks : ', len(ranks))\n",
    "print('follows : ', len(follows))\n",
    "print('followers : ', len(followers))\n",
    "print('weiboes : ', len(weiboes))\n",
    "print('get_times : ', len(get_times))\n",
    "\n",
    "print('-*-    -*-    -*-')\n",
    "\n",
    "print('comment_shares : ', len(comment_shares))\n",
    "print('comment_comments : ', len(comment_comments))\n",
    "print('comment_goods', len(comment_goods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/higashi/PycharmProjects/Scraping/venv/weibo/data')\n",
    "\n",
    "df_feed = pd.DataFrame({\n",
    "    'Account': account_names,\n",
    "    'Location': locations,\n",
    "    'Gender': genders,\n",
    "    'Rank': ranks,\n",
    "    'Follow': follows,\n",
    "    'Follower': followers,\n",
    "    'Weibo': weiboes,\n",
    "    'FeedTime': feed_times,\n",
    "    'GetTime': get_times,\n",
    "    'Type': types,\n",
    "    'Sentence': sentences,\n",
    "    'Mid': mids,\n",
    "    'Share': shares,\n",
    "    'Comment': comments,\n",
    "    'Good': goods\n",
    "})\n",
    "\n",
    "df_comment = pd.DataFrame({\n",
    "    'Account': comment_account_names,\n",
    "    'Location': comment_locations,\n",
    "    'Gender': comment_genders,\n",
    "    'Rank': comment_ranks,\n",
    "    'Follow': comment_follows,\n",
    "    'Follower': comment_followers,\n",
    "    'Weibo': comment_weiboes,\n",
    "    'FeedTime': comment_post_times,\n",
    "    'GetTime': comment_get_times,\n",
    "    'Type': comment_types,\n",
    "    'Sentence': comment_sentences,\n",
    "    'ParentMid': comment_mids,\n",
    "    'Share': comment_shares,\n",
    "    'Comment': comment_comments,\n",
    "    'Good': comment_goods\n",
    "})\n",
    "\n",
    "df_feed.to_csv('20190314_weibo_dprogram_feed' + '.csv')\n",
    "df_comment.to_csv('20190314_weibo_dprogram_comment' + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
